{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv',header=None,)\n",
    "test_df = pd.read_csv('test.csv',header=None,)\n",
    "labels = pd.read_csv('trainLabels.csv',header=None)\n",
    "\n",
    "#connect target to train\n",
    "df['Target'] = labels[0]\n",
    "\n",
    "#Adding id to test set\n",
    "test_df['Id'] = np.arange(len(test_df))\n",
    "test_df['Id'] = test_df['Id']+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.808909</td>\n",
       "      <td>-0.242894</td>\n",
       "      <td>-0.546421</td>\n",
       "      <td>0.255162</td>\n",
       "      <td>1.749736</td>\n",
       "      <td>-0.030458</td>\n",
       "      <td>-1.322071</td>\n",
       "      <td>3.578071</td>\n",
       "      <td>-0.667578</td>\n",
       "      <td>-0.884257</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.224375</td>\n",
       "      <td>-1.675606</td>\n",
       "      <td>-0.479584</td>\n",
       "      <td>-0.244388</td>\n",
       "      <td>-0.672355</td>\n",
       "      <td>0.517860</td>\n",
       "      <td>0.010665</td>\n",
       "      <td>-0.419214</td>\n",
       "      <td>2.818387</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.374101</td>\n",
       "      <td>0.537669</td>\n",
       "      <td>0.081063</td>\n",
       "      <td>0.756773</td>\n",
       "      <td>0.915231</td>\n",
       "      <td>2.557282</td>\n",
       "      <td>3.703187</td>\n",
       "      <td>1.673835</td>\n",
       "      <td>-0.764122</td>\n",
       "      <td>-1.228040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.574154</td>\n",
       "      <td>-2.200519</td>\n",
       "      <td>-1.612240</td>\n",
       "      <td>0.179031</td>\n",
       "      <td>-2.924596</td>\n",
       "      <td>0.643610</td>\n",
       "      <td>-1.470939</td>\n",
       "      <td>-0.067408</td>\n",
       "      <td>-0.976265</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.088370</td>\n",
       "      <td>0.154743</td>\n",
       "      <td>0.380716</td>\n",
       "      <td>-1.176126</td>\n",
       "      <td>1.699867</td>\n",
       "      <td>-0.258627</td>\n",
       "      <td>-1.384999</td>\n",
       "      <td>1.093584</td>\n",
       "      <td>1.596633</td>\n",
       "      <td>0.230631</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005143</td>\n",
       "      <td>1.467490</td>\n",
       "      <td>0.483803</td>\n",
       "      <td>-3.542981</td>\n",
       "      <td>0.814561</td>\n",
       "      <td>-1.652948</td>\n",
       "      <td>1.265866</td>\n",
       "      <td>-1.749248</td>\n",
       "      <td>1.773784</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.685635</td>\n",
       "      <td>0.501283</td>\n",
       "      <td>1.873375</td>\n",
       "      <td>0.215224</td>\n",
       "      <td>-3.983468</td>\n",
       "      <td>-0.103637</td>\n",
       "      <td>4.136113</td>\n",
       "      <td>-0.225431</td>\n",
       "      <td>-1.515015</td>\n",
       "      <td>-1.071763</td>\n",
       "      <td>...</td>\n",
       "      <td>2.386412</td>\n",
       "      <td>-0.131219</td>\n",
       "      <td>0.285646</td>\n",
       "      <td>2.302069</td>\n",
       "      <td>1.255588</td>\n",
       "      <td>-1.563090</td>\n",
       "      <td>-0.125258</td>\n",
       "      <td>-1.030761</td>\n",
       "      <td>-2.945329</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.350867</td>\n",
       "      <td>0.721897</td>\n",
       "      <td>-0.477104</td>\n",
       "      <td>-1.748776</td>\n",
       "      <td>-2.627405</td>\n",
       "      <td>1.075433</td>\n",
       "      <td>4.954253</td>\n",
       "      <td>-3.293501</td>\n",
       "      <td>-0.760369</td>\n",
       "      <td>0.204360</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.045650</td>\n",
       "      <td>-2.173227</td>\n",
       "      <td>0.372992</td>\n",
       "      <td>0.450700</td>\n",
       "      <td>-0.211657</td>\n",
       "      <td>1.301359</td>\n",
       "      <td>-0.522164</td>\n",
       "      <td>2.484883</td>\n",
       "      <td>0.039213</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  2.808909 -0.242894 -0.546421  0.255162  1.749736 -0.030458 -1.322071   \n",
       "1 -0.374101  0.537669  0.081063  0.756773  0.915231  2.557282  3.703187   \n",
       "2 -0.088370  0.154743  0.380716 -1.176126  1.699867 -0.258627 -1.384999   \n",
       "3 -0.685635  0.501283  1.873375  0.215224 -3.983468 -0.103637  4.136113   \n",
       "4  0.350867  0.721897 -0.477104 -1.748776 -2.627405  1.075433  4.954253   \n",
       "\n",
       "          7         8         9  ...        31        32        33        34  \\\n",
       "0  3.578071 -0.667578 -0.884257  ... -0.224375 -1.675606 -0.479584 -0.244388   \n",
       "1  1.673835 -0.764122 -1.228040  ...  0.574154 -2.200519 -1.612240  0.179031   \n",
       "2  1.093584  1.596633  0.230631  ... -0.005143  1.467490  0.483803 -3.542981   \n",
       "3 -0.225431 -1.515015 -1.071763  ...  2.386412 -0.131219  0.285646  2.302069   \n",
       "4 -3.293501 -0.760369  0.204360  ... -2.045650 -2.173227  0.372992  0.450700   \n",
       "\n",
       "         35        36        37        38        39  Id  \n",
       "0 -0.672355  0.517860  0.010665 -0.419214  2.818387   1  \n",
       "1 -2.924596  0.643610 -1.470939 -0.067408 -0.976265   2  \n",
       "2  0.814561 -1.652948  1.265866 -1.749248  1.773784   3  \n",
       "3  1.255588 -1.563090 -0.125258 -1.030761 -2.945329   4  \n",
       "4 -0.211657  1.301359 -0.522164  2.484883  0.039213   5  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([       0,        1,        2,        3,        4,        5,        6,\n",
       "              7,        8,        9,       10,       11,       12,       13,\n",
       "             14,       15,       16,       17,       18,       19,       20,\n",
       "             21,       22,       23,       24,       25,       26,       27,\n",
       "             28,       29,       30,       31,       32,       33,       34,\n",
       "             35,       36,       37,       38,       39, 'Target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [ 0, 1, 2,        3,        4,        5,        6,\n",
    "              7,        8,        9,       10,       11,       12,       13,\n",
    "             14,       15,       16,       17,       18,       19,       20,\n",
    "             21,       22,       23,       24,       25,       26,       27,\n",
    "             28,       29,       30,       31,       32,       33,       34,\n",
    "             35,       36,       37,       38,       39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(df[features], df['Target'], test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = DecisionTreeClassifier()\n",
    "rtm = RandomForestClassifier(n_estimators = 100 , n_jobs = -1)\n",
    "mlp = MLPClassifier()\n",
    "knn = KNeighborsClassifier(3)\n",
    "svm = SVC()\n",
    "gau = GaussianProcessClassifier()\n",
    "ada = AdaBoostClassifier()\n",
    "gaunb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\val\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\val\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.fit(train_X,train_y)\n",
    "rtm.fit(train_X,train_y)\n",
    "mlp.fit(train_X,train_y)\n",
    "knn.fit(train_X,train_y)\n",
    "svm.fit(train_X,train_y)\n",
    "gau.fit(train_X,train_y)\n",
    "ada.fit(train_X,train_y)\n",
    "gaunb.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores with no preprocessing\n",
      "Decision Tress: 0.792\n",
      "Random Forest: 0.844\n",
      "MLPClassifier: 0.904\n",
      "KNeighborsClassifier: 0.888\n",
      "SVC: 0.892\n",
      "GaussianProcessClassifier: 0.888\n",
      "AdaBoostClassifier: 0.804\n",
      "GaussianNB: 0.804\n",
      "\n",
      " Top 3:SVC,GaussianProcessClassifier,MLPClassifier\n"
     ]
    }
   ],
   "source": [
    "#validation score\n",
    "def print_scores():\n",
    "    print('Decision Tress:',dtm.score(val_X, val_y))\n",
    "    print('Random Forest:', rtm.score(val_X, val_y))\n",
    "    print('MLPClassifier:', mlp.score(val_X, val_y))\n",
    "    print('KNeighborsClassifier:', knn.score(val_X, val_y))\n",
    "    print('SVC:', svm.score(val_X, val_y))\n",
    "    print('GaussianProcessClassifier:',gau.score(val_X, val_y))\n",
    "    print('AdaBoostClassifier:',ada.score(val_X, val_y))\n",
    "    print('GaussianNB:',gaunb.score(val_X, val_y))\n",
    "\n",
    "print('Scores with no preprocessing')\n",
    "print_scores()\n",
    "print('\\n Top 3:SVC,GaussianProcessClassifier,MLPClassifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaled_df = scaler.fit_transform(df[features])\n",
    "scaled_test = scaler.fit_transform(test_df[features])\n",
    "\n",
    "scaled_df = pd.DataFrame(scaled_df, columns=df[features].columns)\n",
    "scaled_test = pd.DataFrame(scaled_test, columns=test_df[features].columns)\n",
    "\n",
    "scaled_df['Target'] = labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(scaled_df[features], scaled_df['Target'], test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\val\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\val\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.fit(train_X,train_y)\n",
    "rtm.fit(train_X,train_y)\n",
    "mlp.fit(train_X,train_y)\n",
    "knn.fit(train_X,train_y)\n",
    "svm.fit(train_X,train_y)\n",
    "gau.fit(train_X,train_y)\n",
    "ada.fit(train_X,train_y)\n",
    "gaunb.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores with StandardScaler\n",
      "Decision Tress: 0.74\n",
      "Random Forest: 0.852\n",
      "MLPClassifier: 0.856\n",
      "KNeighborsClassifier: 0.78\n",
      "SVC: 0.852\n",
      "GaussianProcessClassifier: 0.76\n",
      "AdaBoostClassifier: 0.804\n",
      "GaussianNB: 0.812\n",
      "\n",
      " Top 3: Random Forest,SVC,GaussianNB \n"
     ]
    }
   ],
   "source": [
    "#validation score\n",
    "def print_scores():\n",
    "    print('Decision Tress:',dtm.score(val_X, val_y))\n",
    "    print('Random Forest:', rtm.score(val_X, val_y))\n",
    "    print('MLPClassifier:', mlp.score(val_X, val_y))\n",
    "    print('KNeighborsClassifier:', knn.score(val_X, val_y))\n",
    "    print('SVC:', svm.score(val_X, val_y))\n",
    "    print('GaussianProcessClassifier:',gau.score(val_X, val_y))\n",
    "    print('AdaBoostClassifier:',ada.score(val_X, val_y))\n",
    "    print('GaussianNB:',gaunb.score(val_X, val_y))\n",
    "\n",
    "print('Scores with StandardScaler')\n",
    "print_scores()\n",
    "print('\\n Top 3: Random Forest,SVC,GaussianNB ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "normalizer = Normalizer()\n",
    "\n",
    "normalized_df = scaler.fit_transform(df[features])\n",
    "normalized_test = scaler.fit_transform(test_df[features])\n",
    "normalized_df = pd.DataFrame(scaled_df, columns=df[features].columns)\n",
    "normalized_test= pd.DataFrame(normalized_df, columns=test_df[features].columns)\n",
    "normalized_df['Target'] = labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(normalized_df[features], normalized_df['Target'], test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = svm.predict(test_df[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\val\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\val\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.fit(train_X,train_y)\n",
    "rtm.fit(train_X,train_y)\n",
    "mlp.fit(train_X,train_y)\n",
    "knn.fit(train_X,train_y)\n",
    "svm.fit(train_X,train_y)\n",
    "gau.fit(train_X,train_y)\n",
    "ada.fit(train_X,train_y)\n",
    "gaunb.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores with Normalizer\n",
      "Decision Tress: 0.8\n",
      "Random Forest: 0.876\n",
      "MLPClassifier: 0.868\n",
      "KNeighborsClassifier: 0.8\n",
      "SVC: 0.868\n",
      "GaussianProcessClassifier: 0.8\n",
      "AdaBoostClassifier: 0.816\n",
      "GaussianNB: 0.824\n",
      "\n",
      " Top 3:SVC,Random Forest,MLPClassifier\n"
     ]
    }
   ],
   "source": [
    "#validation score\n",
    "def print_scores():\n",
    "    print('Decision Tress:',dtm.score(val_X, val_y))\n",
    "    print('Random Forest:', rtm.score(val_X, val_y))\n",
    "    print('MLPClassifier:', mlp.score(val_X, val_y))\n",
    "    print('KNeighborsClassifier:', knn.score(val_X, val_y))\n",
    "    print('SVC:', svm.score(val_X, val_y))\n",
    "    print('GaussianProcessClassifier:',gau.score(val_X, val_y))\n",
    "    print('AdaBoostClassifier:',ada.score(val_X, val_y))\n",
    "    print('GaussianNB:',gaunb.score(val_X, val_y))\n",
    "\n",
    "print('Scores with Normalizer')\n",
    "print_scores()\n",
    "print('\\n Top 3:SVC,Random Forest,MLPClassifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Grid Search to improve the accuracy\n",
    "\n",
    "We select the algorithms which gave maximum accuracy for further analysis.\n",
    "\n",
    "SVC, GaussianProcessClassifier, MLPClassifier, Random Forest, GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Best Score 0.874\n",
      "Random Forest Best Parmas {'max_depth': 20, 'n_estimators': 200}\n",
      "Random Forest Accuracy 0.874\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "rfc = RandomForestClassifier(random_state=99)\n",
    "\n",
    "#USING GRID SEARCH\n",
    "n_estimators = [10, 50, 100, 200, 400]\n",
    "max_depth = [3, 10, 20, 40]\n",
    "param_grid = dict(n_estimators=n_estimators,max_depth=max_depth)\n",
    "\n",
    "grid_search_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv = 10,scoring='accuracy',n_jobs=-1).fit(df[features], df['Target'])\n",
    "rfc_best = grid_search_rfc.best_estimator_\n",
    "print('Random Forest Best Score',grid_search_rfc.best_score_)\n",
    "print('Random Forest Best Parmas',grid_search_rfc.best_params_)\n",
    "print('Random Forest Accuracy',cross_val_score(rfc_best,df[features],df['Target'], cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Best Score 0.874\n",
      "Random Forest Best Parmas {'max_depth': 20, 'n_estimators': 200}\n",
      "Random Forest Accuracy 0.874\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier - Normalized data\n",
    "rfc = RandomForestClassifier(random_state=99)\n",
    "\n",
    "#USING GRID SEARCH\n",
    "n_estimators = [10, 50, 100, 200, 400]\n",
    "max_depth = [3, 10, 20, 40]\n",
    "param_grid = dict(n_estimators=n_estimators,max_depth=max_depth)\n",
    "\n",
    "grid_search_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv = 10,scoring='accuracy',n_jobs=-1).fit(normalized_df[features], normalized_df['Target'])\n",
    "rfc_best = grid_search_rfc.best_estimator_\n",
    "print('Random Forest Best Score',grid_search_rfc.best_score_)\n",
    "print('Random Forest Best Parmas',grid_search_rfc.best_params_)\n",
    "print('Random Forest Accuracy',cross_val_score(rfc_best,normalized_df[features], normalized_df['Target'], cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Best Score 0.918\n",
      "SVM Best Params {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "SVM Accuracy 0.9180000000000001\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "svc = SVC()\n",
    "\n",
    "#USING GRID SEARCH\n",
    "parameters = [{'kernel':['linear'],'C':[1,10,100]},\n",
    "              {'kernel':['rbf'],'C':[1,10,100],'gamma':[0.05,0.0001,0.01,0.001]}]\n",
    "grid_search_svm = GridSearchCV(estimator=svc, param_grid=parameters, cv = 10, n_jobs=-1,scoring='accuracy').fit(df[features], df['Target'])\n",
    "svm_best = grid_search_svm.best_estimator_\n",
    "print('SVM Best Score',grid_search_svm.best_score_)\n",
    "print('SVM Best Params',grid_search_svm.best_params_)\n",
    "print('SVM Accuracy',cross_val_score(svm_best,df[features], df['Target'], cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Best Score 0.911\n",
      "KNN Best Params {'n_neighbors': 3}\n",
      "KNN Accuracy 0.9109999999999999\n"
     ]
    }
   ],
   "source": [
    "#KNN \n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "#USING GRID SEARCH\n",
    "n_neighbors=[3,5,6,7,8,9,10]\n",
    "param_grid = dict(n_neighbors=n_neighbors)\n",
    "\n",
    "grid_search_knn = GridSearchCV(estimator=knn, param_grid=param_grid, cv = 10, n_jobs=-1,scoring='accuracy').fit(df[features], df['Target'])\n",
    "knn_best = grid_search_knn.best_estimator_\n",
    "print('KNN Best Score', grid_search_knn.best_score_)\n",
    "print('KNN Best Params',grid_search_knn.best_params_)\n",
    "print('KNN Accuracy',cross_val_score(knn_best,df[features], df['Target'], cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(C=10, gamma=0.01,kernel ='rbf')\n",
    "svm.fit(df[features],df['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'svm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-35fede1c6a0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'svm' is not defined"
     ]
    }
   ],
   "source": [
    "predictions = svm.predict(test_df[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe with predictions\n",
    "kaggle = pd.DataFrame({'key':test_df['key'],'fare_amount': fare_amount})\n",
    "\n",
    "# save to csv\n",
    "kaggle.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
